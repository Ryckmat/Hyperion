#!/usr/bin/env python3
"""Script pour afficher les specs compl√®tes du PC."""

import platform
import subprocess
import os
from pathlib import Path


def run_command(cmd):
    """Execute une commande et retourne le r√©sultat."""
    try:
        result = subprocess.run(
            cmd,
            shell=True,
            capture_output=True,
            text=True,
            timeout=5
        )
        return result.stdout.strip()
    except Exception as e:
        return f"Erreur: {e}"


def get_cpu_info():
    """Informations CPU."""
    print("üñ•Ô∏è  CPU")
    print("=" * 60)
    
    # Mod√®le CPU
    cpu_model = run_command("lscpu | grep 'Model name' | cut -d ':' -f2 | xargs")
    print(f"   Mod√®le      : {cpu_model}")
    
    # Nombre de c≈ìurs
    cores = run_command("nproc")
    print(f"   C≈ìurs       : {cores}")
    
    # Architecture
    arch = platform.machine()
    print(f"   Architecture: {arch}")
    
    # Fr√©quence
    freq = run_command("lscpu | grep 'MHz' | head -1 | awk '{print $3}'")
    if freq:
        print(f"   Fr√©quence   : {freq} MHz")
    
    print()


def get_memory_info():
    """Informations RAM."""
    print("üíæ RAM")
    print("=" * 60)
    
    # RAM totale
    mem_total = run_command("free -h | grep Mem | awk '{print $2}'")
    print(f"   Total       : {mem_total}")
    
    # RAM utilis√©e
    mem_used = run_command("free -h | grep Mem | awk '{print $3}'")
    print(f"   Utilis√©e    : {mem_used}")
    
    # RAM disponible
    mem_available = run_command("free -h | grep Mem | awk '{print $7}'")
    print(f"   Disponible  : {mem_available}")
    
    print()


def get_gpu_info():
    """Informations GPU."""
    print("üéÆ GPU")
    print("=" * 60)
    
    # V√©rifier si nvidia-smi existe
    nvidia_check = run_command("which nvidia-smi")
    
    if nvidia_check and "nvidia-smi" in nvidia_check:
        # GPU NVIDIA d√©tect√©
        gpu_name = run_command("nvidia-smi --query-gpu=name --format=csv,noheader")
        gpu_memory = run_command("nvidia-smi --query-gpu=memory.total --format=csv,noheader")
        gpu_driver = run_command("nvidia-smi --query-gpu=driver_version --format=csv,noheader")
        
        print(f"   Mod√®le      : {gpu_name}")
        print(f"   VRAM        : {gpu_memory}")
        print(f"   Driver      : {gpu_driver}")
        print(f"   CUDA        : ‚úÖ Disponible")
    else:
        # Pas de GPU NVIDIA, chercher AMD ou Intel
        gpu_info = run_command("lspci | grep -i vga")
        print(f"   D√©tect√©     : {gpu_info}")
        print(f"   CUDA        : ‚ùå Non disponible")
    
    print()


def get_disk_info():
    """Informations disque."""
    print("üíø DISQUE")
    print("=" * 60)
    
    # Espace total et disponible
    disk_info = run_command("df -h / | tail -1")
    parts = disk_info.split()
    
    if len(parts) >= 4:
        print(f"   Total       : {parts[1]}")
        print(f"   Utilis√©     : {parts[2]}")
        print(f"   Disponible  : {parts[3]}")
        print(f"   Utilisation : {parts[4]}")
    
    print()


def get_os_info():
    """Informations syst√®me."""
    print("üêß SYST√àME")
    print("=" * 60)
    
    # Distribution
    distro = run_command("lsb_release -d | cut -d ':' -f2 | xargs")
    print(f"   Distribution: {distro}")
    
    # Kernel
    kernel = platform.release()
    print(f"   Kernel      : {kernel}")
    
    # Python
    python_version = platform.python_version()
    print(f"   Python      : {python_version}")
    
    print()


def check_ai_capabilities():
    """V√©rifie les capacit√©s pour l'IA."""
    print("ü§ñ CAPACIT√âS IA")
    print("=" * 60)
    
    # RAM disponible
    mem_available_gb = run_command("free -g | grep Mem | awk '{print $7}'")
    
    try:
        mem_gb = int(mem_available_gb)
        
        print(f"   RAM dispo   : {mem_gb} GB")
        print()
        print("   Mod√®les recommand√©s :")
        
        if mem_gb >= 16:
            print("   ‚úÖ Llama 3.2 (8B)    : Excellente qualit√©")
            print("   ‚úÖ Qwen 2.5 (7B)     : Tr√®s bon en code")
            print("   ‚úÖ Mistral (7B)      : Rapide")
        elif mem_gb >= 8:
            print("   ‚úÖ Llama 3.2 (3B)    : Bonne qualit√©, l√©ger")
            print("   ‚úÖ Phi-3 Mini (3.8B) : Excellent, optimis√©")
            print("   ‚ö†Ô∏è  Mod√®les 7B       : Possible mais lent")
        else:
            print("   ‚ö†Ô∏è  RAM insuffisante pour LLM locaux")
            print("   üí° Utiliser API Claude recommand√©")
    except:
        print("   ‚ùì Impossible de d√©terminer RAM disponible")
    
    print()
    
    # GPU
    nvidia_check = run_command("which nvidia-smi")
    if nvidia_check and "nvidia-smi" in nvidia_check:
        vram = run_command("nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits")
        try:
            vram_gb = int(vram) // 1024
            print(f"   GPU VRAM    : {vram_gb} GB")
            
            if vram_gb >= 8:
                print("   ‚úÖ Inference GPU : Tr√®s rapide (recommand√©)")
            elif vram_gb >= 4:
                print("   ‚úÖ Inference GPU : Rapide")
            else:
                print("   ‚ö†Ô∏è  VRAM limit√©e  : CPU recommand√©")
        except:
            pass
    else:
        print("   ‚ÑπÔ∏è  Pas de GPU NVIDIA : Inference CPU uniquement")
    
    print()


def main():
    """Affiche toutes les specs."""
    print()
    print("=" * 60)
    print("üìä SP√âCIFICATIONS PC - ANALYSE HYPERION")
    print("=" * 60)
    print()
    
    get_os_info()
    get_cpu_info()
    get_memory_info()
    get_gpu_info()
    get_disk_info()
    check_ai_capabilities()
    
    print("=" * 60)
    print("‚úÖ ANALYSE TERMIN√âE")
    print("=" * 60)
    print()


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()

#!/bin/bash
# hyperion-model-setup.sh - Configuration automatique des modÃ¨les LLM

set -e

echo "ğŸ¯ Configuration du modÃ¨le LLM pour Hyperion v2.5.0"
echo "=============================================="
echo ""

# VÃ©rifier que Ollama est installÃ©
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollama n'est pas installÃ©. Installez-le d'abord:"
    echo "   curl -fsSL https://ollama.ai/install.sh | sh"
    exit 1
fi

# VÃ©rifier que Ollama fonctionne
if ! ollama list &> /dev/null; then
    echo "âŒ Ollama ne rÃ©pond pas. DÃ©marrez le service:"
    echo "   ollama serve"
    exit 1
fi

echo "ğŸ“Š Profils d'usage disponibles:"
echo ""
echo "1) ğŸƒâ€â™‚ï¸ Performance Ultra-Rapide (<3s)"
echo "   ModÃ¨le: llama3.2:1b (1.3GB)"
echo "   Usage: Exploration rapide, dÃ©monstrations"
echo ""
echo "2) âš–ï¸ Ã‰quilibre Performance/QualitÃ© (5-10s)"
echo "   ModÃ¨le: llama3.1:8b (4.7GB)"
echo "   Usage: DÃ©veloppement quotidien, code reviews"
echo ""
echo "3) ğŸ§  QualitÃ© Premium (10-30s)"
echo "   ModÃ¨le: qwen2.5:14b (8.7GB)"
echo "   Usage: Analyses approfondies, architecture"
echo ""
echo "4) ğŸš€ Expert/Recherche (30s+)"
echo "   ModÃ¨le: qwen2.5:32b (19GB)"
echo "   Usage: Audits, recherche, analyses complexes"
echo ""
echo "5) ğŸ“‹ Afficher la configuration actuelle"
echo ""

read -p "Votre choix (1-5): " choice

case $choice in
    1)
        MODEL="llama3.2:1b"
        TOKENS="128"
        TEMP="0.0"
        TIMEOUT="2"
        DESCRIPTION="Performance Ultra-Rapide"
        ;;
    2)
        MODEL="llama3.1:8b"
        TOKENS="512"
        TEMP="0.1"
        TIMEOUT="10"
        DESCRIPTION="Ã‰quilibre Performance/QualitÃ©"
        ;;
    3)
        MODEL="qwen2.5:14b"
        TOKENS="1024"
        TEMP="0.1"
        TIMEOUT="30"
        DESCRIPTION="QualitÃ© Premium"
        ;;
    4)
        MODEL="qwen2.5:32b"
        TOKENS="2048"
        TEMP="0.2"
        TIMEOUT="60"
        DESCRIPTION="Expert/Recherche"
        ;;
    5)
        echo ""
        echo "ğŸ“‹ Configuration actuelle:"
        echo "========================="
        if [ -f "src/hyperion/modules/rag/config.py" ]; then
            echo "ModÃ¨le: $(grep 'OLLAMA_MODEL.*=' src/hyperion/modules/rag/config.py | cut -d'"' -f2)"
            echo "Max Tokens: $(grep 'LLM_MAX_TOKENS.*=' src/hyperion/modules/rag/config.py | cut -d'(' -f2 | cut -d')' -f1)"
            echo "TempÃ©rature: $(grep 'LLM_TEMPERATURE.*=' src/hyperion/modules/rag/config.py | cut -d'(' -f2 | cut -d')' -f1)"
            echo "Timeout: $(grep 'LLM_TIMEOUT.*=' src/hyperion/modules/rag/config.py | cut -d'(' -f2 | cut -d')' -f1)"
        else
            echo "âŒ Fichier de configuration non trouvÃ©"
        fi
        exit 0
        ;;
    *)
        echo "âŒ Choix invalide"
        exit 1
        ;;
esac

echo ""
echo "âœ… Configuration sÃ©lectionnÃ©e: $DESCRIPTION"
echo "ğŸ“¦ ModÃ¨le: $MODEL"
echo ""

# VÃ©rifier si le modÃ¨le est dÃ©jÃ  tÃ©lÃ©chargÃ©
if ollama list | grep -q "$MODEL"; then
    echo "âœ… ModÃ¨le $MODEL dÃ©jÃ  disponible"
else
    echo "ğŸ“¥ TÃ©lÃ©chargement du modÃ¨le $MODEL..."
    echo "â³ Cela peut prendre plusieurs minutes selon la taille..."

    # TÃ©lÃ©charger avec une barre de progression visible
    ollama pull "$MODEL"

    if [ $? -eq 0 ]; then
        echo "âœ… ModÃ¨le $MODEL tÃ©lÃ©chargÃ© avec succÃ¨s"
    else
        echo "âŒ Ã‰chec du tÃ©lÃ©chargement du modÃ¨le $MODEL"
        exit 1
    fi
fi

# CrÃ©er un backup de la configuration actuelle
if [ -f "src/hyperion/modules/rag/config.py" ]; then
    cp "src/hyperion/modules/rag/config.py" "src/hyperion/modules/rag/config.py.backup.$(date +%Y%m%d_%H%M%S)"
    echo "ğŸ’¾ Backup de la configuration crÃ©Ã©"
fi

# Mettre Ã  jour la configuration
echo "ğŸ“ Mise Ã  jour de la configuration..."

CONFIG_FILE="src/hyperion/modules/rag/config.py"

# CrÃ©er une version temporaire avec les nouvelles valeurs
sed "s/OLLAMA_MODEL.*=.*$/OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"$MODEL\")/g" "$CONFIG_FILE" | \
sed "s/LLM_MAX_TOKENS.*=.*$/LLM_MAX_TOKENS = int(os.getenv(\"LLM_MAX_TOKENS\", \"$TOKENS\"))/g" | \
sed "s/LLM_TEMPERATURE.*=.*$/LLM_TEMPERATURE = float(os.getenv(\"LLM_TEMPERATURE\", \"$TEMP\"))/g" | \
sed "s/LLM_TIMEOUT.*=.*$/LLM_TIMEOUT = int(os.getenv(\"LLM_TIMEOUT\", \"$TIMEOUT\"))/g" > "$CONFIG_FILE.tmp"

# Remplacer le fichier original
mv "$CONFIG_FILE.tmp" "$CONFIG_FILE"

echo "âœ… Configuration mise Ã  jour:"
echo "   - ModÃ¨le: $MODEL"
echo "   - Max Tokens: $TOKENS"
echo "   - TempÃ©rature: $TEMP"
echo "   - Timeout: $TIMEOUT secondes"
echo ""

# VÃ©rifier si l'API Hyperion est en cours d'exÃ©cution
if pgrep -f "hyperion.api.main" > /dev/null; then
    echo "ğŸ”„ RedÃ©marrage de l'API Hyperion..."
    pkill -f "hyperion.api.main"
    sleep 2

    # RedÃ©marrer en arriÃ¨re-plan
    cd "$(dirname "$0")/.."
    python -m hyperion.api.main &
    API_PID=$!

    echo "â³ Attente du dÃ©marrage de l'API..."
    sleep 5

    # VÃ©rifier que l'API rÃ©pond
    if curl -s http://localhost:8000/api/health > /dev/null; then
        echo "âœ… API Hyperion redÃ©marrÃ©e avec succÃ¨s (PID: $API_PID)"

        # Test rapide du nouveau modÃ¨le
        echo "ğŸ§ª Test du nouveau modÃ¨le..."
        RESPONSE=$(curl -s -X POST "http://localhost:8000/api/chat" \
            -H "Content-Type: application/json" \
            -d '{"question":"Test de configuration","repo":"test"}' | \
            python -c "import json, sys; data=json.load(sys.stdin); print(data.get('answer', data.get('detail', 'Pas de rÃ©ponse'))[:100])" 2>/dev/null)

        if [ $? -eq 0 ] && [ ! -z "$RESPONSE" ]; then
            echo "âœ… Test rÃ©ussi - ModÃ¨le fonctionnel"
            echo "ğŸ“ RÃ©ponse: $RESPONSE..."
        else
            echo "âš ï¸ Test partiel - API dÃ©marrÃ©e mais modÃ¨le peut nÃ©cessiter plus de temps"
        fi
    else
        echo "âš ï¸ API redÃ©marrÃ©e mais pas encore accessible"
        echo "   VÃ©rifiez manuellement: curl http://localhost:8000/api/health"
    fi
else
    echo "â„¹ï¸ API Hyperion non en cours d'exÃ©cution"
    echo "   DÃ©marrez-la manuellement: python -m hyperion.api.main"
fi

echo ""
echo "ğŸ‰ Configuration terminÃ©e!"
echo ""
echo "ğŸ“š Documentation complÃ¨te: MODEL_SELECTION_GUIDE.md"
echo "ğŸ”§ Pour changer de modÃ¨le ultÃ©rieurement, relancez ce script"
echo ""
echo "ğŸ’¡ Conseils d'optimisation:"
echo "   - Utilisez GPU pour les gros modÃ¨les: export EMBEDDING_DEVICE=cuda"
echo "   - Surveillez l'utilisation RAM avec: htop ou nvidia-smi"
echo "   - Testez les performances: time curl -X POST localhost:8000/api/chat ..."
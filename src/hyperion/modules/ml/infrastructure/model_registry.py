"""
Model Registry pour gestion des mod√®les ML avec versioning et m√©tadonn√©es.

Syst√®me professionnel de gestion des mod√®les ML avec:
- Versioning des mod√®les
- M√©tadonn√©es et m√©triques
- Sauvegarde/chargement s√©curis√©
- Int√©gration MLFlow
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Any

import joblib
import mlflow
from pydantic import BaseModel

from .ml_config import ml_config


class ModelMetadata(BaseModel):
    """M√©tadonn√©es d'un mod√®le ML."""

    name: str
    version: str
    model_type: str
    created_at: datetime
    created_by: str = "hyperion-ml-system"

    # M√©triques performance
    accuracy: float | None = None
    precision: float | None = None
    recall: float | None = None
    f1_score: float | None = None

    # Informations entra√Ænement
    training_features: list[str] = []
    training_samples: int | None = None
    hyperparameters: dict[str, Any] = {}

    # Statut et validation
    status: str = "trained"  # trained, validated, production, deprecated
    validation_results: dict[str, Any] = {}

    # Tags et description
    tags: dict[str, str] = {}
    description: str | None = None

    class Config:
        arbitrary_types_allowed = True


class ModelRegistry:
    """
    Registry professionnel pour mod√®les ML avec int√©gration MLFlow.

    G√®re le cycle de vie complet des mod√®les:
    - Sauvegarde avec m√©tadonn√©es
    - Versioning automatique
    - Tracking MLFlow
    - Validation et promotion
    """

    def __init__(self):
        """Initialise le registry."""
        self.models_dir = ml_config.models_dir
        self.metadata_dir = self.models_dir / "metadata"
        self.metadata_dir.mkdir(exist_ok=True)

        # Configuration MLFlow
        mlflow.set_tracking_uri(ml_config.mlflow.tracking_uri)
        self._ensure_mlflow_experiment()

    def _ensure_mlflow_experiment(self):
        """S'assurer que l'exp√©rience MLFlow existe."""
        try:
            experiment = mlflow.get_experiment_by_name(ml_config.mlflow.experiment_name)
            if experiment is None:
                experiment_id = mlflow.create_experiment(
                    ml_config.mlflow.experiment_name, artifact_location=ml_config.mlflow.artifact_location
                )
                print(f"‚úÖ Exp√©rience MLFlow cr√©√©e: {experiment_id}")
            else:
                print(f"üìã Exp√©rience MLFlow existante: {experiment.experiment_id}")
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur configuration MLFlow: {e}")

    def save_model(
        self,
        model: Any,
        name: str,
        model_type: str,
        metadata: dict[str, Any] | None = None,
        version: str | None = None,
        mlflow_logging: bool = True,
    ) -> str:
        """
        Sauvegarde un mod√®le avec m√©tadonn√©es compl√®tes.

        Args:
            model: Mod√®le ML √† sauvegarder
            name: Nom du mod√®le
            model_type: Type du mod√®le (RandomForest, XGBoost, etc.)
            metadata: M√©tadonn√©es additionnelles
            version: Version explicite (auto-incr√©ment√©e si None)
            mlflow_logging: Activer logging MLFlow

        Returns:
            Version du mod√®le sauvegard√©
        """
        # G√©n√©rer version si non fournie
        if version is None:
            version = self._generate_version(name)

        # Pr√©parer m√©tadonn√©es
        model_metadata = ModelMetadata(
            name=name, version=version, model_type=model_type, created_at=datetime.now(), **(metadata or {})
        )

        # Chemins de sauvegarde
        model_filename = f"{name}_v{version}.pkl"
        model_path = self.models_dir / model_filename
        metadata_path = self.metadata_dir / f"{name}_v{version}_metadata.json"

        try:
            # Sauvegarder mod√®le
            if hasattr(model, "save_model"):
                # XGBoost/LightGBM natif
                model.save_model(str(model_path))
            else:
                # Scikit-learn et autres (joblib pour performance)
                joblib.dump(model, model_path, compress=3)

            # Sauvegarder m√©tadonn√©es
            metadata_dict = model_metadata.dict()
            # Convertir datetime en string pour JSON
            if "created_at" in metadata_dict and isinstance(metadata_dict["created_at"], datetime):
                metadata_dict["created_at"] = metadata_dict["created_at"].isoformat()

            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump(metadata_dict, f, indent=2, ensure_ascii=False)

            # Logging MLFlow si activ√©
            if mlflow_logging:
                self._log_to_mlflow(model, model_metadata, model_path)

            print(f"‚úÖ Mod√®le sauvegard√©: {name} v{version}")
            print(f"   üìÅ Fichier: {model_path}")
            print(f"   üìã M√©tadonn√©es: {metadata_path}")

            return version

        except Exception as e:
            print(f"‚ùå Erreur sauvegarde mod√®le {name}: {e}")
            # Nettoyer fichiers partiels
            for path in [model_path, metadata_path]:
                if path.exists():
                    path.unlink()
            raise

    def load_model(
        self, name: str, version: str | None = None, return_metadata: bool = False
    ) -> Any | tuple[Any, ModelMetadata]:
        """
        Charge un mod√®le avec version sp√©cifique ou latest.

        Args:
            name: Nom du mod√®le
            version: Version sp√©cifique (latest si None)
            return_metadata: Retourner aussi les m√©tadonn√©es

        Returns:
            Mod√®le charg√© (et m√©tadonn√©es si demand√©es)
        """
        # D√©terminer version √† charger
        if version is None:
            version = self._get_latest_version(name)
            if version is None:
                raise ValueError(f"Aucun mod√®le trouv√© pour {name}")

        # Chemins
        model_filename = f"{name}_v{version}.pkl"
        model_path = self.models_dir / model_filename
        metadata_path = self.metadata_dir / f"{name}_v{version}_metadata.json"

        if not model_path.exists():
            raise FileNotFoundError(f"Mod√®le non trouv√©: {model_path}")

        try:
            # Charger mod√®le
            model = joblib.load(model_path)

            # Charger m√©tadonn√©es si demand√©es
            if return_metadata:
                if metadata_path.exists():
                    with open(metadata_path, encoding="utf-8") as f:
                        metadata_dict = json.load(f)

                    # Convertir string datetime en datetime object
                    if "created_at" in metadata_dict and isinstance(metadata_dict["created_at"], str):
                        metadata_dict["created_at"] = datetime.fromisoformat(metadata_dict["created_at"])

                    metadata = ModelMetadata(**metadata_dict)
                else:
                    # M√©tadonn√©es basiques si fichier manquant
                    metadata = ModelMetadata(
                        name=name, version=version, model_type="unknown", created_at=datetime.now()
                    )

                return model, metadata
            else:
                return model

        except Exception as e:
            print(f"‚ùå Erreur chargement mod√®le {name} v{version}: {e}")
            raise

    def list_models(self) -> list[dict[str, Any]]:
        """Liste tous les mod√®les disponibles avec leurs m√©tadonn√©es."""
        models_info = []

        for metadata_file in self.metadata_dir.glob("*_metadata.json"):
            try:
                with open(metadata_file, encoding="utf-8") as f:
                    metadata = json.load(f)

                # Convertir string datetime en datetime object si n√©cessaire
                if "created_at" in metadata and isinstance(metadata["created_at"], str):
                    metadata["created_at"] = datetime.fromisoformat(metadata["created_at"])

                # V√©rifier existence fichier mod√®le
                model_filename = f"{metadata['name']}_v{metadata['version']}.pkl"
                model_path = self.models_dir / model_filename
                metadata["file_exists"] = model_path.exists()
                metadata["file_size_mb"] = (
                    round(model_path.stat().st_size / (1024 * 1024), 2) if model_path.exists() else 0
                )

                models_info.append(metadata)

            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lecture m√©tadonn√©es {metadata_file}: {e}")
                continue

        # Trier par nom puis version
        models_info.sort(key=lambda x: (x["name"], x["version"]))
        return models_info

    def get_model_info(self, name: str, version: str | None = None) -> dict[str, Any]:
        """R√©cup√®re les informations d√©taill√©es d'un mod√®le."""
        if version is None:
            version = self._get_latest_version(name)

        metadata_path = self.metadata_dir / f"{name}_v{version}_metadata.json"
        if not metadata_path.exists():
            raise FileNotFoundError(f"M√©tadonn√©es non trouv√©es pour {name} v{version}")

        with open(metadata_path, encoding="utf-8") as f:
            info = json.load(f)

        # Convertir string datetime en datetime object si n√©cessaire
        if "created_at" in info and isinstance(info["created_at"], str):
            info["created_at"] = datetime.fromisoformat(info["created_at"])

        # Ajouter informations fichier
        model_filename = f"{name}_v{version}.pkl"
        model_path = self.models_dir / model_filename
        info["file_exists"] = model_path.exists()
        if model_path.exists():
            stat = model_path.stat()
            info["file_size_mb"] = round(stat.st_size / (1024 * 1024), 2)
            info["file_modified"] = datetime.fromtimestamp(stat.st_mtime).isoformat()

        return info

    def promote_model(self, name: str, version: str, status: str = "production"):
        """Promeut un mod√®le vers un nouveau statut."""
        metadata_path = self.metadata_dir / f"{name}_v{version}_metadata.json"
        if not metadata_path.exists():
            raise FileNotFoundError(f"Mod√®le non trouv√©: {name} v{version}")

        # Charger et mettre √† jour m√©tadonn√©es
        with open(metadata_path, encoding="utf-8") as f:
            metadata = json.load(f)

        # Convertir string datetime en datetime object si n√©cessaire
        if "created_at" in metadata and isinstance(metadata["created_at"], str):
            metadata["created_at"] = datetime.fromisoformat(metadata["created_at"])

        old_status = metadata.get("status", "unknown")
        metadata["status"] = status
        metadata["promoted_at"] = datetime.now().isoformat()

        # Convertir datetime en string pour JSON
        if 'created_at' in metadata and isinstance(metadata['created_at'], datetime):
            metadata['created_at'] = metadata['created_at'].isoformat()

        # Sauvegarder
        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

        print(f"‚úÖ Mod√®le {name} v{version} promu: {old_status} ‚Üí {status}")

    def delete_model(self, name: str, version: str, confirm: bool = False):
        """Supprime un mod√®le et ses m√©tadonn√©es."""
        if not confirm:
            raise ValueError("Suppression requiert confirm=True pour s√©curit√©")

        model_filename = f"{name}_v{version}.pkl"
        model_path = self.models_dir / model_filename
        metadata_path = self.metadata_dir / f"{name}_v{version}_metadata.json"

        deleted_files = []
        for path in [model_path, metadata_path]:
            if path.exists():
                path.unlink()
                deleted_files.append(path.name)

        if deleted_files:
            print(f"‚úÖ Fichiers supprim√©s: {deleted_files}")
        else:
            print(f"‚ö†Ô∏è Aucun fichier trouv√© pour {name} v{version}")

    def _generate_version(self, name: str) -> str:
        """G√©n√®re une nouvelle version pour un mod√®le."""
        existing_versions = []

        for metadata_file in self.metadata_dir.glob(f"{name}_v*_metadata.json"):
            try:
                version_str = metadata_file.stem.split(f"{name}_v")[1].split("_metadata")[0]
                existing_versions.append(version_str)
            except (IndexError, ValueError):
                continue

        if not existing_versions:
            return "1.0.0"

        # Trouver la version la plus r√©cente et incr√©menter
        try:
            # Trier par version s√©mantique
            from packaging import version

            versions = [version.parse(v) for v in existing_versions]
            latest = max(versions)

            # Incr√©menter version mineure
            return f"{latest.major}.{latest.minor + 1}.0"

        except Exception:
            # Fallback: incr√©menter simplement
            return f"1.{len(existing_versions)}.0"

    def _get_latest_version(self, name: str) -> str | None:
        """R√©cup√®re la derni√®re version d'un mod√®le."""
        versions = []

        for metadata_file in self.metadata_dir.glob(f"{name}_v*_metadata.json"):
            try:
                version_str = metadata_file.stem.split(f"{name}_v")[1].split("_metadata")[0]
                versions.append(version_str)
            except (IndexError, ValueError):
                continue

        if not versions:
            return None

        try:
            from packaging import version

            parsed_versions = [version.parse(v) for v in versions]
            latest = max(parsed_versions)
            return str(latest)
        except Exception:
            # Fallback: trier alphab√©tiquement
            return sorted(versions)[-1]

    def _log_to_mlflow(self, model: Any, metadata: ModelMetadata, model_path: Path):
        """Log mod√®le et m√©tadonn√©es vers MLFlow."""
        try:
            with mlflow.start_run():
                # Log hyperparam√®tres
                if metadata.hyperparameters:
                    for param, value in metadata.hyperparameters.items():
                        mlflow.log_param(param, value)

                # Log m√©triques
                metrics_to_log = {
                    "accuracy": metadata.accuracy,
                    "precision": metadata.precision,
                    "recall": metadata.recall,
                    "f1_score": metadata.f1_score,
                }
                for metric, value in metrics_to_log.items():
                    if value is not None:
                        mlflow.log_metric(metric, value)

                # Log tags
                tags = {
                    "model_name": metadata.name,
                    "model_version": metadata.version,
                    "model_type": metadata.model_type,
                    "status": metadata.status,
                    **metadata.tags,
                    **ml_config.mlflow.default_tags,
                }
                mlflow.set_tags(tags)

                # Log artifact (mod√®le)
                mlflow.log_artifact(str(model_path), artifact_path="models")

                # Log mod√®le avec format natif si possible
                try:
                    if hasattr(model, "fit"):  # Scikit-learn style
                        mlflow.sklearn.log_model(model, "sklearn_model")
                except Exception:
                    pass  # Ignore si pas support√©

        except Exception as e:
            print(f"‚ö†Ô∏è Erreur logging MLFlow: {e}")


# Instance globale du registry
model_registry = ModelRegistry()

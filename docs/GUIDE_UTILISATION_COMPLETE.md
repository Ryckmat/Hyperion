# Guide d'Utilisation Compl√®te - Hyperion v2.5.0 Enterprise Ready

## Table des mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Installation et configuration](#installation-et-configuration)
3. [Utilisation CLI](#utilisation-cli)
4. [Infrastructure ML](#infrastructure-ml)
5. [API et int√©grations](#api-et-int√©grations)
6. [Dashboard et interfaces](#dashboard-et-interfaces)
7. [D√©pannage et maintenance](#d√©pannage-et-maintenance)
8. [Exemples pratiques](#exemples-pratiques)

---

## Vue d'ensemble

Hyperion v2.5.0 Enterprise Ready est une plateforme d'analyse de code avanc√©e qui combine :

- **Analyse Git intelligente** avec m√©triques approfondies
- **Infrastructure ML compl√®te** avec pr√©diction de risques et d√©tection d'anomalies
- **RAG (Retrieval Augmented Generation)** pour interrogation contextuelle
- **API OpenAI-compatible** pour int√©gration avec outils externes
- **Dashboard interactif** et interface conversationnelle

### Nouveaut√©s v2.5.0

- ‚úÖ **Infrastructure ML Enterprise** : MLflow, Feature Store, Training Pipeline
- ‚úÖ **4 mod√®les ML op√©rationnels** : RiskPredictor, AnomalyDetector, ImpactAnalyzer, BugPredictor
- ‚úÖ **35+ features ML** pr√™tes pour analyse avanc√©e
- ‚úÖ **138 tests valid√©s** avec couverture compl√®te
- ‚úÖ **Standards entreprise** : Black/Ruff formatting

---

## Installation et configuration

### Pr√©requis syst√®me

```bash
# V√©rifier les pr√©requis
python --version  # >= 3.10 requis
docker --version  # Pour Qdrant et Neo4j
git --version     # Pour analyse des repos
```

### Installation rapide

```bash
# 1. Cloner le projet
git clone https://github.com/Ryckmat/Hyperion.git
cd Hyperion

# 2. Installation Python
pip install -e . --break-system-packages

# 3. V√©rification
hyperion --version
hyperion info
```

### Configuration avanc√©e

```bash
# Variables d'environnement (optionnel)
export HYPERION_LOG_LEVEL=INFO
export HYPERION_ML_BACKEND=mlflow
export HYPERION_FEATURE_STORE_CACHE=true

# Configuration Neo4j (optionnel)
export NEO4J_URI=bolt://localhost:7687
export NEO4J_USER=neo4j
export NEO4J_PASSWORD=votre_password
```

### V√©rification installation

```bash
# Test complet installation
python -m pytest tests/ -v
# Doit afficher : 138 tests PASSED

# Test CLI
hyperion info
# Doit afficher la configuration compl√®te
```

---

## Utilisation CLI

### Commandes principales

```bash
# Aide g√©n√©rale
hyperion --help

# Version
hyperion --version

# Informations syst√®me
hyperion info
```

### Analyse d'un repository

```bash
# Analyse basique
hyperion profile /path/to/repo

# Analyse avec nom personnalis√©
hyperion profile /path/to/repo --name="MonProjet"

# Analyse avec sortie sp√©cifique
hyperion profile /path/to/repo --output=/tmp/analysis
```

**Exemple d√©taill√© :**

```bash
# Analyser le repo actuel
hyperion profile . --name="Hyperion-Self-Analysis"

# Sortie attendue :
# üîç Analyse du d√©p√¥t : /home/user/Hyperion
# ‚úÖ Analyse termin√©e !
#    ‚Ä¢ Repo          : Hyperion-Self-Analysis
#    ‚Ä¢ Commits       : 51
#    ‚Ä¢ Contributeurs : 1
#    ‚Ä¢ Profil YAML   : data/repositories/Hyperion-Self-Analysis/profile.yaml
```

### G√©n√©ration de documentation

```bash
# Documentation Markdown
hyperion generate data/repositories/MonProjet/profile.yaml --format markdown

# Documentation HTML
hyperion generate data/repositories/MonProjet/profile.yaml --format html

# Sortie personnalis√©e
hyperion generate profile.yaml --format markdown --output=/tmp/docs
```

### Ingestion Neo4j

```bash
# Ingestion simple
hyperion ingest data/repositories/MonProjet/profile.yaml

# Ingestion avec nettoyage
hyperion ingest profile.yaml --clear

# Ingestion multiple
for profile in data/repositories/*/profile.yaml; do
    hyperion ingest "$profile"
done
```

### Export de donn√©es

```bash
# Export releases
hyperion export /path/to/repo

# Export avec filtre
hyperion export /path/to/repo --since="2024-01-01"
```

---

## Infrastructure ML

### Vue d'ensemble ML

Hyperion v2.5.0 inclut une infrastructure ML compl√®te avec :

- **MLflow** : Tracking et registry de mod√®les
- **Feature Store** : Gestion centralis√©e des features
- **Training Pipeline** : Entra√Ænement automatis√©
- **Data Validator** : Validation et monitoring

### Utilisation Feature Store

```python
from hyperion.modules.ml.infrastructure.feature_store import FeatureStore

# Initialisation
feature_store = FeatureStore()

# Stockage de features
features = {
    'complexity_score': 0.75,
    'bug_history_count': 5,
    'test_coverage': 0.85
}
feature_store.store_features('mon-repo', features, source_file='analysis.py')

# R√©cup√©ration de features
stored_features = feature_store.get_features('mon-repo')
print(f"Features disponibles : {len(stored_features)}")
```

### Entra√Ænement de mod√®les

```python
from hyperion.modules.ml.training.training_pipeline import TrainingPipeline

# Initialisation pipeline
pipeline = TrainingPipeline()

# Entra√Ænement mod√®le de risque
results = pipeline.train_risk_predictor()
print(f"Pr√©cision du mod√®le : {results['metrics']['accuracy']:.2%}")

# Sauvegarde automatique avec MLflow
model_uri = results.get('model_uri')
print(f"Mod√®le sauv√© : {model_uri}")
```

### Pr√©diction de risques

```python
from hyperion.modules.impact.predictor import ImpactPredictor

# Pr√©diction sur fichier
predictor = ImpactPredictor()
risk_score = predictor.predict_risk('src/module/important.py')

print(f"Score de risque : {risk_score:.2%}")
if risk_score > 0.7:
    print("‚ö†Ô∏è  Fichier √† haut risque - Review recommand√©e")
```

### D√©tection d'anomalies

```python
from hyperion.modules.anomaly.detector import AnomalyDetector

# Analyse d'anomalies
detector = AnomalyDetector()
anomalies = detector.detect_anomalies('src/')

for anomaly in anomalies:
    print(f"üîç {anomaly['file']} : {anomaly['type']} (score: {anomaly['score']:.2f})")
```

### Configuration ML

```yaml
# config/ml_config.yaml
models:
  risk_predictor:
    type: "RandomForest"
    hyperparameters:
      n_estimators: 100
      max_depth: 10
      random_state: 42

  anomaly_detector:
    type: "IsolationForest"
    hyperparameters:
      contamination: 0.1
      random_state: 42

features:
  target_features:
    - complexity_score
    - bug_history_count
    - test_coverage
    - commit_frequency
```

---

## API et int√©grations

### Lancement de l'API

```bash
# API seule
python scripts/dev/run_api.py

# API avec dashboard
python scripts/dev/run_dashboard.py

# Orchestration compl√®te
./scripts/deploy/hyperion_master.sh
```

### Endpoints disponibles

#### API Core
- `GET /` - Informations API
- `GET /api/health` - Health check
- `GET /api/repos` - Liste des repositories analys√©s
- `GET /api/repos/{repo_name}` - D√©tails d'un repository
- `POST /api/chat` - Chat RAG

#### API OpenAI-Compatible
- `GET /v1/models` - Liste des mod√®les
- `POST /v1/chat/completions` - Chat completions

### Utilisation API

```bash
# Test health check
curl http://localhost:8000/api/health

# Liste des repos
curl http://localhost:8000/api/repos | jq .

# Chat RAG
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "hyperion-rag",
    "messages": [
      {"role": "user", "content": "Quels sont les fichiers les plus risqu√©s ?"}
    ]
  }' | jq .
```

### Int√©gration Python

```python
import requests

# Client API
class HyperionClient:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url

    def get_repos(self):
        response = requests.get(f"{self.base_url}/api/repos")
        return response.json()

    def chat(self, message):
        response = requests.post(f"{self.base_url}/v1/chat/completions", json={
            "model": "hyperion-rag",
            "messages": [{"role": "user", "content": message}]
        })
        return response.json()

# Utilisation
client = HyperionClient()
repos = client.get_repos()
print(f"Repositories analys√©s : {len(repos)}")

response = client.chat("Analyse le fichier le plus complexe")
print(response['choices'][0]['message']['content'])
```

---

## Dashboard et interfaces

### Lancement des interfaces

```bash
# Dashboard React (port 3000)
cd frontend
python -m http.server 3000

# Open WebUI (port 3001)
# Automatique via hyperion_master.sh

# API Documentation (port 8000)
# Disponible sur http://localhost:8000/docs
```

### Utilisation Open WebUI

1. **Acc√®s** : http://localhost:3001
2. **Configuration** :
   - Mod√®le : `hyperion-rag`
   - Aucune cl√© API requise
3. **Requ√™tes exemples** :
   ```
   Quels sont les hotspots du repository ?
   Analyse les risques du fichier src/main.py
   Quels d√©veloppeurs ont le plus contribu√© ?
   D√©tecte les anomalies dans le code
   ```

### Dashboard React

1. **Acc√®s** : http://localhost:3000
2. **Fonctionnalit√©s** :
   - Vue d'ensemble des repositories
   - M√©triques en temps r√©el
   - Graphiques d'activit√©
   - Export de rapports

---

## D√©pannage et maintenance

### Tests et validation

```bash
# Tests complets
python -m pytest tests/ -v

# Tests ML sp√©cifiques
python -m pytest tests/unit/test_*ml* -v

# Tests API
python -m pytest tests/api/ -v

# Tests avec couverture
python -m pytest tests/ --cov=src/hyperion --cov-report=html
```

### Formatage et qualit√©

```bash
# Formatage Black
black src/ tests/ scripts/

# V√©rification Ruff
ruff check src/ tests/ scripts/

# Correction automatique
ruff check --fix src/ tests/ scripts/
```

### Logs et monitoring

```bash
# Logs API
tail -f logs/api.log

# Logs ML
tail -f logs/ml/training.log

# Logs dashboard
tail -f logs/dashboard.log
```

### Nettoyage

```bash
# Nettoyage cache
rm -rf logs/ml/cache/
rm -rf data/ml/feature_store/cache/

# Reset MLflow
rm -rf mlruns/

# Nettoyage complet
make clean  # Si Makefile disponible
```

### Probl√®mes courants

**1. Tests ML √©chouent**
```bash
# V√©rifier d√©pendances ML
python -c "import mlflow, sklearn, xgboost; print('OK')"

# R√©installer d√©pendances
pip install -e . --force-reinstall
```

**2. API ne d√©marre pas**
```bash
# V√©rifier port
lsof -i :8000

# Tuer processus existant
pkill -f "uvicorn.*hyperion"
```

**3. Features ML manquantes**
```bash
# R√©g√©n√©rer features
python -c "
from hyperion.modules.ml.infrastructure.feature_store import FeatureStore
fs = FeatureStore()
fs.rebuild_cache()
"
```

---

## Exemples pratiques

### Workflow complet d'analyse

```bash
#!/bin/bash
# Script d'analyse compl√®te

REPO_PATH="/path/to/your/repo"
REPO_NAME="MyProject"

echo "üöÄ D√©marrage analyse compl√®te de $REPO_NAME"

# 1. Profilage Git
echo "üìä Profilage Git..."
hyperion profile "$REPO_PATH" --name="$REPO_NAME"

# 2. G√©n√©ration documentation
echo "üìù G√©n√©ration documentation..."
hyperion generate "data/repositories/$REPO_NAME/profile.yaml" --format markdown

# 3. Ingestion Neo4j (optionnel)
echo "üíæ Ingestion Neo4j..."
hyperion ingest "data/repositories/$REPO_NAME/profile.yaml"

# 4. Analyse ML
echo "ü§ñ Analyse ML..."
python -c "
from hyperion.modules.impact.predictor import ImpactPredictor
from hyperion.modules.anomaly.detector import AnomalyDetector

# Pr√©diction risques
predictor = ImpactPredictor()
risks = predictor.analyze_repository('$REPO_PATH')
print(f'Fichiers √† haut risque : {len([r for r in risks if r[\"risk\"] > 0.7])}')

# D√©tection anomalies
detector = AnomalyDetector()
anomalies = detector.scan_repository('$REPO_PATH')
print(f'Anomalies d√©tect√©es : {len(anomalies)}')
"

echo "‚úÖ Analyse termin√©e !"
echo "üåê Dashboard : http://localhost:3000"
echo "üí¨ Chat : http://localhost:3001"
echo "üìö API Docs : http://localhost:8000/docs"
```

### Monitoring continu

```python
#!/usr/bin/env python3
"""Script de monitoring continu Hyperion."""

import time
import schedule
from pathlib import Path
from hyperion.core.git_analyzer import GitAnalyzer
from hyperion.modules.ml.infrastructure.feature_store import FeatureStore

class HyperionMonitor:
    def __init__(self, repos_to_monitor):
        self.repos = repos_to_monitor
        self.feature_store = FeatureStore()

    def analyze_repo(self, repo_path):
        """Analyse p√©riodique d'un repo."""
        print(f"üîç Analyse de {repo_path}")

        analyzer = GitAnalyzer(repo_path)
        profile = analyzer.analyze()

        # Stockage des m√©triques
        features = {
            'commits_count': profile['git_summary']['commits'],
            'contributors_count': profile['git_summary']['contributors'],
            'recent_activity': profile['git_summary']['recent_commits_90d']
        }

        self.feature_store.store_features(
            repo_name=Path(repo_path).name,
            features=features,
            source_file='monitor'
        )

        print(f"‚úÖ {Path(repo_path).name} analys√©")

    def daily_analysis(self):
        """Analyse quotidienne."""
        for repo in self.repos:
            self.analyze_repo(repo)

    def weekly_report(self):
        """Rapport hebdomadaire."""
        print("üìä G√©n√©ration rapport hebdomadaire...")
        # Logique de rapport

    def start_monitoring(self):
        """D√©marrage du monitoring."""
        # Analyse quotidienne √† 9h
        schedule.every().day.at("09:00").do(self.daily_analysis)

        # Rapport hebdomadaire le lundi √† 8h
        schedule.every().monday.at("08:00").do(self.weekly_report)

        print("üöÄ Monitoring d√©marr√©")
        while True:
            schedule.run_pending()
            time.sleep(60)

# Configuration
repos_to_monitor = [
    "/path/to/repo1",
    "/path/to/repo2"
]

monitor = HyperionMonitor(repos_to_monitor)
monitor.start_monitoring()
```

### Int√©gration CI/CD

```yaml
# .github/workflows/hyperion-analysis.yml
name: Hyperion Code Analysis

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  hyperion-analysis:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0  # N√©cessaire pour analyse Git compl√®te

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install Hyperion
      run: |
        pip install git+https://github.com/Ryckmat/Hyperion.git

    - name: Run Analysis
      run: |
        hyperion profile . --name="CI-Analysis-${{ github.sha }}"
        hyperion generate data/repositories/CI-Analysis-${{ github.sha }}/profile.yaml --format markdown

    - name: ML Risk Analysis
      run: |
        python -c "
        from hyperion.modules.impact.predictor import ImpactPredictor
        predictor = ImpactPredictor()
        risks = predictor.analyze_repository('.')
        high_risks = [r for r in risks if r['risk'] > 0.8]
        if high_risks:
            print(f'‚ö†Ô∏è {len(high_risks)} fichiers √† tr√®s haut risque d√©tect√©s')
            for risk in high_risks[:5]:  # Top 5
                print(f'  - {risk[\"file\"]}: {risk[\"risk\"]:.2%}')
            exit(1) if len(high_risks) > 10 else exit(0)
        "

    - name: Upload Analysis
      uses: actions/upload-artifact@v3
      with:
        name: hyperion-analysis
        path: docs/generated/
```

---

## Support et ressources

### Documentation
- **Guide Architecture** : `docs/architecture/architecture.md`
- **Plan v3.0** : `docs/v3.0-enterprise-plan.md`
- **API Reference** : http://localhost:8000/docs
- **Code Examples** : `scripts/dev/`

### Communaut√©
- **Issues GitHub** : [GitHub Issues](https://github.com/Ryckmat/Hyperion/issues)
- **Discussions** : [GitHub Discussions](https://github.com/Ryckmat/Hyperion/discussions)

### Maintenance
- **Tests r√©guliers** : `python -m pytest tests/`
- **Updates** : `git pull && pip install -e .`
- **Monitoring** : Logs dans `logs/`

---

**Hyperion v2.5.0 Enterprise Ready** - Analyse de code intelligente avec infrastructure ML compl√®te.

Derni√®re mise √† jour : 25 d√©cembre 2024
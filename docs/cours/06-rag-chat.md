# ğŸ¤– Chapitre 06 - RAG et Chat

**Interroger vos repos avec l'IA** - MaÃ®triser le Retrieval Augmented Generation

*â±ï¸ DurÃ©e estimÃ©e : 30 minutes*

---

## ğŸ¯ **Objectifs de ce Chapitre**

Ã€ la fin de ce chapitre, vous maÃ®triserez :
- âœ… Le fonctionnement du RAG (Retrieval Augmented Generation)
- âœ… Comment poser les bonnes questions pour obtenir de meilleures rÃ©ponses
- âœ… InterprÃ©ter les sources et la contextualisation
- âœ… Utiliser diffÃ©rentes interfaces de chat (Web, API, intÃ©grations)

---

## ğŸ§  **Comprendre le RAG**

### ğŸ” **Qu'est-ce que le RAG ?**

**RAG** = Retrieval Augmented Generation = **GÃ©nÃ©ration AugmentÃ©e par Recherche**

```
Votre Question
     â†“
ğŸ” Recherche dans la base de connaissance (votre code)
     â†“
ğŸ“Š RÃ©cupÃ©ration des passages pertinents
     â†“
ğŸ¤– LLM gÃ©nÃ¨re une rÃ©ponse basÃ©e sur ces sources
     â†“
ğŸ’¬ RÃ©ponse + Sources exactes
```

### ğŸ—ï¸ **Architecture RAG Hyperion**

```
Repository Git
     â†“
ğŸ“„ Extraction documentation + code
     â†“
âœ‚ï¸ DÃ©coupage en chunks (512 tokens)
     â†“
ğŸ§® Vectorisation (embeddings)
     â†“
ğŸ—„ï¸ Stockage Qdrant (base vectorielle)
     â†“
ğŸ” Recherche similaritÃ© cosinus
     â†“
ğŸ¤– LLM local (Ollama) + contexte
```

### âš¡ **Avantages du RAG Local**

- âœ… **RÃ©ponses prÃ©cises** : BasÃ©es sur VOTRE code exactement
- âœ… **Sources tracÃ©es** : Fichier et ligne exacte pour chaque info
- âœ… **Contexte prÃ©servÃ©** : Comprend l'architecture de votre projet
- âœ… **100% privÃ©** : Aucune donnÃ©e n'est envoyÃ©e Ã  l'extÃ©rieur
- âœ… **Temps rÃ©el** : Toujours Ã  jour avec votre derniÃ¨re version

---

## ğŸ’¬ **Interfaces de Chat**

### ğŸŒ **Interface Web (RecommandÃ©e)**

```bash
# DÃ©marrer Hyperion
hyperion serve

# Ouvrir dans le navigateur
# http://localhost:8000/chat
```

**FonctionnalitÃ©s Web :**
- ğŸ’¬ Chat en temps rÃ©el
- ğŸ“ Affichage des sources cliquables
- ğŸ” Historique des conversations
- ğŸ“Š MÃ©triques de pertinence
- ğŸ¯ Suggestions de questions

### ğŸ“± **Chat via API**

```bash
# Question simple
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Comment ajouter une nouvelle route ?",
    "repository": "mon-projet"
  }'

# Chat avec contexte
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Et comment gÃ©rer les erreurs sur cette route ?",
    "repository": "mon-projet",
    "conversation_id": "conv-123"
  }'
```

### ğŸ”— **IntÃ©grations Externes**

#### ğŸ’¬ **Open WebUI (Interface ChatGPT-like)**

```bash
# DÃ©marrer Open WebUI connectÃ© Ã  Hyperion
docker run -d -p 3001:8080 \
  -e OPENAI_API_BASE_URL=http://localhost:8000/api/openai \
  -e OPENAI_API_KEY=hyperion-local \
  ghcr.io/open-webui/open-webui:main

# AccÃ©der Ã  http://localhost:3001
```

#### ğŸ¤– **Discord Bot**

```python
import discord
import openai

openai.api_base = "http://localhost:8000/api/openai"

class CodeBot(discord.Client):
    async def on_message(self, message):
        if message.author == self.user:
            return

        if message.content.startswith('!code'):
            question = message.content[5:]  # Enlever '!code'

            response = openai.ChatCompletion.create(
                model="hyperion-rag",
                messages=[
                    {"role": "user", "content": question}
                ]
            )

            await message.reply(response.choices[0].message.content)

bot = CodeBot()
bot.run('YOUR_DISCORD_TOKEN')
```

---

## ğŸ¯ **Poser les Bonnes Questions**

### âœ… **Questions Efficaces**

#### ğŸ—ï¸ **Architecture et Structure**
```
âœ… "Comment est organisÃ© ce projet ?"
âœ… "OÃ¹ se trouve la logique de l'authentification ?"
âœ… "Quels sont les modules principaux et leurs responsabilitÃ©s ?"
âœ… "Comment les donnÃ©es circulent-elles dans l'application ?"
```

#### ğŸ”§ **ImplÃ©mentation Pratique**
```
âœ… "Comment ajouter une nouvelle API endpoint ?"
âœ… "OÃ¹ et comment configurer la base de donnÃ©es ?"
âœ… "Comment implÃ©menter la validation des donnÃ©es ?"
âœ… "Quels sont les patterns utilisÃ©s pour la gestion des erreurs ?"
```

#### ğŸ§ª **Tests et QualitÃ©**
```
âœ… "Comment Ã©crire des tests pour ce module ?"
âœ… "OÃ¹ sont les exemples de tests existants ?"
âœ… "Comment mocker les dÃ©pendances externes ?"
âœ… "Quelle est la stratÃ©gie de tests de ce projet ?"
```

#### ğŸ“š **Documentation et Exemples**
```
âœ… "Montre-moi des exemples d'utilisation de cette fonction"
âœ… "Comment configurer l'environnement de dÃ©veloppement ?"
âœ… "Quelles sont les conventions de code de ce projet ?"
âœ… "Comment dÃ©ployer cette application ?"
```

### âŒ **Questions Moins Efficaces**

```
âŒ "Comment Ã§a marche ?" (trop vague)
âŒ "OÃ¹ est le code ?" (pas de contexte)
âŒ "C'est quoi ce truc ?" (pas constructif)
âŒ "Peut tu dÃ©bugger Ã§a ?" (sans contexte du bug)
```

### ğŸ’¡ **Techniques pour AmÃ©liorer vos Questions**

#### ğŸ¯ **Soyez SpÃ©cifique**
```
âŒ "Comment gÃ©rer les erreurs ?"
âœ… "Comment gÃ©rer les erreurs 404 dans les API endpoints ?"

âŒ "OÃ¹ est la config ?"
âœ… "OÃ¹ se trouve la configuration de la base de donnÃ©es ?"
```

#### ğŸ“ **Donnez du Contexte**
```
âœ… "Je veux ajouter une validation email sur le formulaire d'inscription.
    Comment faire Ã§a dans ce projet ?"

âœ… "J'ai une erreur 'Connection refused' lors du test de l'API.
    Comment debugger les problÃ¨mes de connexion ?"
```

#### ğŸ”„ **Questions de Suivi**
```
1ï¸âƒ£ "Comment ajouter une nouvelle route ?"
2ï¸âƒ£ "Et comment ajouter des middlewares Ã  cette route ?"
3ï¸âƒ£ "Comment tester cette route avec des donnÃ©es mockÃ©es ?"
```

---

## ğŸ“Š **Comprendre les RÃ©ponses**

### ğŸ¯ **Anatomie d'une RÃ©ponse Hyperion**

```
ğŸ¤– Hyperion: Pour ajouter une nouvelle route dans cette application Flask :

ğŸ“ **MÃ©thode recommandÃ©e :**

1. **CrÃ©er la route dans un blueprint** (recommandÃ© pour ce projet)
   ```python
   # Dans src/blueprints/api.py
   @api_bp.route('/nouvelle-route', methods=['GET', 'POST'])
   def ma_nouvelle_route():
       return jsonify({"message": "Hello World"})
   ```

2. **Enregistrer le blueprint** (dÃ©jÃ  fait dans ce projet)
   Le blueprint est enregistrÃ© dans `src/app.py` ligne 25

3. **Ajouter la validation** (pattern utilisÃ© dans ce projet)
   Utiliser `marshmallow` comme dans les autres endpoints

ğŸ“ **Sources exactes :**
- src/blueprints/api.py:15-30 (exemples similaires)
- src/app.py:25 (enregistrement blueprint)
- src/schemas/api_schemas.py:10-25 (validation patterns)
- docs/api.md:45-60 (documentation patterns)

ğŸ’¡ **Bonnes pratiques de ce projet :**
- Utiliser les blueprints pour l'organisation
- Validation avec marshmallow
- Tests dans tests/test_api.py
```

### ğŸ” **InterprÃ©ter les Sources**

#### ğŸ“‚ **Types de Sources**
- **Code source** : `.py`, `.js`, `.java` - ImplÃ©mentation rÃ©elle
- **Documentation** : `.md`, `.rst`, `.txt` - Explications
- **Configuration** : `.yaml`, `.json`, `.env` - ParamÃ¨tres
- **Tests** : `test_*.py`, `*.spec.js` - Exemples d'usage

#### ğŸ“Š **Score de Pertinence**
```
ğŸŸ¢ 0.8-1.0 : TrÃ¨s pertinent, source directe
ğŸŸ¡ 0.6-0.8 : Pertinent, contexte utile
ğŸŸ  0.4-0.6 : Moyennement pertinent
ğŸ”´ <0.4   : Peu pertinent (peut Ãªtre ignorÃ©)
```

#### ğŸ¯ **Actions RecommandÃ©es**
- **Score >0.8** â†’ Examiner ce fichier en prioritÃ©
- **Multiple sources** â†’ Pattern confirmÃ© dans le projet
- **Sources rÃ©centes** â†’ Approche actuelle du projet
- **Sources de tests** â†’ Exemples d'utilisation validÃ©s

---

## âš¡ **Optimiser les Performances du Chat**

### ğŸš€ **Configuration Performance**

```yaml
# config.yaml
rag:
  # ModÃ¨le d'embedding (vitesse vs qualitÃ©)
  embedding_model: "all-MiniLM-L6-v2"  # Rapide
  # embedding_model: "all-mpnet-base-v2"  # Plus prÃ©cis mais lent

  # Taille des chunks
  chunk_size: 512        # Plus petit = plus prÃ©cis
  chunk_overlap: 50      # Chevauchement pour continuitÃ©

  # Recherche
  top_k_results: 5       # Nombre de sources rÃ©cupÃ©rÃ©es
  similarity_threshold: 0.6  # Seuil de pertinence

  # LLM
  max_tokens: 1000       # Longueur max rÃ©ponse
  temperature: 0.1       # CrÃ©ativitÃ© (0 = factuel, 1 = crÃ©atif)
```

### âš¡ **Modes de Vitesse**

```bash
# Mode ultra-rapide (<3s)
curl -X POST http://localhost:8000/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Comment ajouter une route ?",
    "repository": "mon-projet",
    "speed_mode": "ultra_fast"
  }'

# Mode Ã©quilibrÃ© (5-10s)
curl -X POST http://localhost:8000/api/chat \
  -d '{"speed_mode": "balanced"}'

# Mode prÃ©cision maximale (10-30s)
curl -X POST http://localhost:8000/api/chat \
  -d '{"speed_mode": "high_precision"}'
```

### ğŸ“Š **Cache et Optimisations**

```python
# Client avec cache intelligent
class CachedHyperionChat:
    def __init__(self):
        self.cache = {}
        self.base_url = "http://localhost:8000"

    def ask(self, question, repository, use_cache=True):
        # VÃ©rifier cache
        cache_key = f"{repository}:{hash(question)}"
        if use_cache and cache_key in self.cache:
            print("ğŸ“¦ RÃ©ponse depuis cache")
            return self.cache[cache_key]

        # RequÃªte API
        response = requests.post(f"{self.base_url}/api/chat", json={
            "message": question,
            "repository": repository
        })

        result = response.json()

        # Mettre en cache
        if use_cache:
            self.cache[cache_key] = result

        return result

# Usage avec cache
chat = CachedHyperionChat()
answer1 = chat.ask("Comment ajouter une route ?", "flask-app")
answer2 = chat.ask("Comment ajouter une route ?", "flask-app")  # Depuis cache
```

---

## ğŸ”§ **Configuration AvancÃ©e du RAG**

### ğŸ¯ **Personnalisation par Repository**

```yaml
# .hyperion/repo-config.yaml dans votre projet
rag_config:
  # Focus sur certains types de fichiers
  include_patterns:
    - "*.py"
    - "*.md"
    - "docs/**"
    - "README*"

  # Exclure certains dossiers
  exclude_patterns:
    - "node_modules/**"
    - "venv/**"
    - "*.log"

  # Contexte personnalisÃ©
  system_context: |
    Tu es un assistant spÃ©cialisÃ© dans ce projet Flask.
    Ce projet utilise SQLAlchemy, Marshmallow et pytest.
    RÃ©ponds toujours en franÃ§ais et donne des exemples de code.

  # Prompts spÃ©cialisÃ©s
  prompt_templates:
    architecture: "Explique l'architecture de {file} dans le contexte de ce projet Flask"
    testing: "Comment tester {function} en utilisant pytest et les patterns de ce projet ?"
```

### ğŸ¨ **ModÃ¨les LLM SpÃ©cialisÃ©s**

```bash
# ModÃ¨les disponibles par profil d'usage
ollama list

# Ultra-rapide (<3s) - DÃ©veloppement quotidien
llama3.2:1b

# Ã‰quilibrÃ© (5-10s) - Analyses moyennes
llama3.1:8b

# PrÃ©cis (10-30s) - Analyses complexes
qwen2.5:14b

# Expert (30s+) - Architecture et refactoring
qwen2.5:32b
```

### ğŸ”„ **SÃ©lection Automatique de ModÃ¨le**

```python
def choose_model_for_question(question):
    """Choisir le bon modÃ¨le selon la complexitÃ©"""

    # Questions simples â†’ modÃ¨le rapide
    simple_patterns = [
        "oÃ¹ se trouve",
        "comment importer",
        "quelle commande",
        "oÃ¹ est dÃ©fini"
    ]

    # Questions complexes â†’ modÃ¨le prÃ©cis
    complex_patterns = [
        "architecture",
        "refactoring",
        "performance",
        "conception"
    ]

    question_lower = question.lower()

    if any(pattern in question_lower for pattern in complex_patterns):
        return "qwen2.5:14b"  # ModÃ¨le prÃ©cis
    elif any(pattern in question_lower for pattern in simple_patterns):
        return "llama3.2:1b"  # ModÃ¨le rapide
    else:
        return "llama3.1:8b"  # ModÃ¨le Ã©quilibrÃ©
```

---

## ğŸ“± **IntÃ©grations AvancÃ©es**

### ğŸ’¬ **Bot Slack Intelligent**

```python
from slack_bolt import App
import openai

app = App(token=os.environ["SLACK_BOT_TOKEN"])
openai.api_base = "http://localhost:8000/api/openai"

@app.event("app_mention")
def handle_mention(event, say):
    # Extraire repository du nom du channel
    channel_name = event.get('channel_name', 'general')
    repo_name = channel_name.replace('-', '_')  # slack-bot â†’ slack_bot

    # Question de l'utilisateur
    question = event['text'].split('>', 1)[1].strip()  # Enlever la mention

    # Contexte Slack
    user_id = event['user']

    response = openai.ChatCompletion.create(
        model="hyperion-rag",
        messages=[
            {
                "role": "system",
                "content": f"Tu es l'assistant du repository {repo_name}. "
                          f"RÃ©ponds Ã  <@{user_id}> de maniÃ¨re concise pour Slack."
            },
            {"role": "user", "content": question}
        ],
        max_tokens=500,  # LimitÃ© pour Slack
        temperature=0.1
    )

    answer = response.choices[0].message.content

    # Format Slack avec sources
    say(f"ğŸ¤– *Hyperion ({repo_name})*\n\n{answer}")

# RÃ©actions rapides
@app.event("reaction_added")
def handle_reaction(event):
    if event['reaction'] == 'hyperion':
        # Auto-analyser le message
        # ... logique d'analyse automatique
        pass
```

### ğŸ¯ **Extension VSCode AvancÃ©e**

```typescript
// extension.ts
import * as vscode from 'vscode';

export function activate(context: vscode.ExtensionContext) {
    // Provider pour hover avec Hyperion
    const hoverProvider = vscode.languages.registerHoverProvider('*', {
        provideHover(document, position, token) {
            const wordRange = document.getWordRangeAtPosition(position);
            if (!wordRange) return;

            const word = document.getText(wordRange);
            const line = document.lineAt(position.line);

            // Poser question contextuelle Ã  Hyperion
            const question = `Explique la fonction "${word}" dans le fichier ${document.fileName}`;

            return queryHyperion(question).then(response => {
                return new vscode.Hover([
                    new vscode.MarkdownString(`**Hyperion**: ${response}`)
                ]);
            });
        }
    });

    // Commande pour analyser selection
    const analyzeCommand = vscode.commands.registerCommand('hyperion.analyzeSelection', async () => {
        const editor = vscode.window.activeTextEditor;
        if (!editor) return;

        const selection = editor.selection;
        const selectedText = editor.document.getText(selection);

        if (selectedText) {
            const question = `Analyse ce code et explique ce qu'il fait:\n\n${selectedText}`;
            const response = await queryHyperion(question);

            // Afficher dans un panel
            const panel = vscode.window.createWebviewPanel(
                'hyperion',
                'Hyperion Analysis',
                vscode.ViewColumn.Two,
                {}
            );

            panel.webview.html = `
                <html>
                <body>
                    <h2>ğŸ¤– Hyperion Analysis</h2>
                    <div style="white-space: pre-wrap;">${response}</div>
                </body>
                </html>
            `;
        }
    });

    context.subscriptions.push(hoverProvider, analyzeCommand);
}

async function queryHyperion(question: string): Promise<string> {
    // Implementation de la requÃªte HTTP vers Hyperion
    // ...
}
```

---

## ğŸ‰ **MaÃ®trise du RAG et Chat !**

### âœ… **Ce que Vous MaÃ®trisez Maintenant**

- ğŸ§  **RAG Concepts** : Comment fonctionne la recherche augmentÃ©e
- ğŸ’¬ **Questions Efficaces** : Techniques pour obtenir de meilleures rÃ©ponses
- ğŸ” **Sources et Contexte** : InterprÃ©ter et exploiter les rÃ©sultats
- âš¡ **Performance** : Optimiser vitesse et prÃ©cision
- ğŸ”§ **Configuration** : Personnaliser le comportement pour vos projets
- ğŸ“± **IntÃ©grations** : Slack, Discord, VSCode, et plus

### ğŸš€ **Utilisations AvancÃ©es**

- Assistant de dÃ©veloppement personnalisÃ©
- Onboarding automatique des nouvelles recrues
- Documentation interactive
- Code review assistÃ© par IA
- Knowledge base d'Ã©quipe

### ğŸ“š **Prochaines Ã‰tapes**

ğŸ‘‰ **Continuez avec** : [Chapitre 07 - Infrastructure ML](07-infrastructure-ml.md)

Au prochain chapitre, vous dÃ©couvrirez :
- Les 5 modÃ¨les ML d'Hyperion en dÃ©tail
- Feature engineering et prÃ©dictions
- MLflow et model registry
- Optimisation des modÃ¨les pour votre contexte

---

*Parfait ! Vous maÃ®trisez maintenant le chat intelligent avec votre code. Rendez-vous au [Chapitre 07](07-infrastructure-ml.md) !* ğŸ¤–

---

*Cours Hyperion v2.7.0 - Chapitre 06*
# ðŸ”§ Code Quality Standards - Hyperion v3.0

![Quality](https://img.shields.io/badge/Code_Quality-100%25-green.svg)
![Ruff](https://img.shields.io/badge/Ruff-0_errors-green.svg)
![Black](https://img.shields.io/badge/Black-100%25-green.svg)
![Tests](https://img.shields.io/badge/Tests-189/189-green.svg)

Guide complet des standards de qualitÃ© code pour Hyperion v3.0 Enterprise.

---

## ðŸŽ¯ **Standards Enterprise Atteints**

### âœ… **MÃ©triques QualitÃ© Actuelles**
- **Ruff Linting** : âœ… **0 erreurs** (100% compliance)
- **Black Formatting** : âœ… **148/148 fichiers** compliant
- **Tests** : âœ… **189/189 tests** passing (100% success)
- **Type Coverage** : âœ… **95%+** annotations

### ðŸ“Š **Indicateurs ClÃ©s**
```bash
# VÃ©rification complÃ¨te (tout doit passer)
ruff check src/ tests/     # âœ… All checks passed!
black --check src/ tests/  # âœ… 148 files would be left unchanged
pytest tests/ -v          # âœ… 189 passed in X.XXs
```

---

## ðŸ› ï¸ **Outils de QualitÃ©**

### 1. **Ruff - Linter Ultra-Rapide**

#### Configuration (.ruff.toml)
```toml
[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.lint]
select = [
    "E",    # pycodestyle errors
    "W",    # pycodestyle warnings
    "F",    # pyflakes
    "I",    # isort
    "B",    # flake8-bugbear
    "C4",   # flake8-comprehensions
    "UP",   # pyupgrade
    "SIM",  # flake8-simplify
    "ARG",  # flake8-unused-arguments
]
ignore = [
    "E501",   # line-too-long (handled by black)
    "E203",   # whitespace before ':' (conflicts with black)
]

[tool.ruff.lint.per-file-ignores]
"tests/**/*.py" = ["ARG001", "ARG002"]  # Unused args OK in tests
"**/__init__.py" = ["F401"]             # Unused imports OK in __init__
```

#### Commandes Essentielles
```bash
# VÃ©rification complÃ¨te
ruff check src/ tests/

# Auto-fix automatique
ruff check src/ tests/ --fix

# Check specific rules
ruff check src/ --select=F821,F841,E722

# Format imports
ruff check src/ --select=I --fix
```

### 2. **Black - Formatage Code**

#### Configuration (pyproject.toml)
```toml
[tool.black]
line-length = 100
target-version = ['py311']
include = '\.pyi?$'
extend-exclude = '''
/(
    \.git
  | \.mypy_cache
  | \.tox
  | venv
  | \.venv
  | _build
  | buck-out
  | build
  | dist
)/
'''
```

#### Commandes Essentielles
```bash
# VÃ©rification formatage
black --check src/ tests/

# Application formatage
black src/ tests/

# Diff avant formatage
black --diff src/ tests/

# Check specific file
black --check src/hyperion/api/main.py
```

### 3. **Pytest - Tests Enterprise**

#### Configuration (pytest.ini)
```ini
[tool:pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts =
    --strict-markers
    --disable-warnings
    --tb=short
    -ra
markers =
    slow: marks tests as slow
    integration: marks tests as integration tests
    architecture: marks tests as architecture validation
```

#### Structure Tests
```
tests/
â”œâ”€â”€ api/                    # Tests API Gateway v3.0
â”œâ”€â”€ architecture/           # Tests architecture v3.0
â”œâ”€â”€ integration/            # Tests intÃ©gration
â”œâ”€â”€ rag/                   # Tests RAG v2.9
â”œâ”€â”€ unit/                  # Tests unitaires
â””â”€â”€ validation/            # Tests validation
```

---

## ðŸ“‹ **RÃ¨gles de QualitÃ© Enterprise**

### ðŸš¨ **Erreurs Critiques (0 TolÃ©rÃ©)**

#### F821 - Undefined Names
```python
# âŒ Mauvais
for user_id, data in items():
    process(user_id)  # user_id utilisÃ© mais pas dÃ©fini dans scope

# âœ… Bon
for user_id, data in items():
    process(user_id)  # user_id correctement dÃ©fini
```

#### F841 - Unused Variables
```python
# âŒ Mauvais
result = calculate_something()  # Variable assignÃ©e mais jamais utilisÃ©e

# âœ… Bon
result = calculate_something()
return result

# âœ… Alternative
_ = calculate_something()  # Explicitement marquÃ© comme non utilisÃ©
```

#### E722 - Bare Except
```python
# âŒ Mauvais
try:
    risky_operation()
except:  # Attrape tout, masque les erreurs
    pass

# âœ… Bon
try:
    risky_operation()
except Exception as e:  # SpÃ©cifique avec chaÃ®nage
    raise ProcessError(f"Failed: {e}") from e
```

### âš ï¸ **Standards Style (100% Compliance)**

#### SIM102 - Nested If Statements
```python
# âŒ Mauvais
if condition1:
    if condition2:
        do_something()

# âœ… Bon
if condition1 and condition2:
    do_something()
```

#### SIM108 - Ternary Operator
```python
# âŒ Mauvais
if condition:
    result = value1
else:
    result = value2

# âœ… Bon
result = value1 if condition else value2
```

#### ARG002 - Unused Arguments
```python
# âŒ Mauvais
def process(data, config):  # config non utilisÃ©
    return transform(data)

# âœ… Bon
def process(data, _config):  # MarquÃ© explicitement
    return transform(data)

# âœ… Alternative
def process(data, config):
    _ = config  # MarquÃ© dans le corps
    return transform(data)
```

### ðŸ”§ **Exception Chaining (B904)**
```python
# âŒ Mauvais
try:
    operation()
except Exception as e:
    raise CustomError(f"Failed: {e}")  # Perd la stack trace

# âœ… Bon
try:
    operation()
except Exception as e:
    raise CustomError(f"Failed: {e}") from e  # PrÃ©serve stack trace
```

---

## ðŸ”„ **Workflow QualitÃ©**

### 1. **Pre-commit Hooks**

#### Setup (.pre-commit-config.yaml)
```yaml
repos:
  - repo: https://github.com/charliermarsh/ruff-pre-commit
    rev: v0.1.7
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]
      - id: ruff-format

  - repo: https://github.com/psf/black
    rev: 23.12.0
    hooks:
      - id: black
        language_version: python3.11

  - repo: local
    hooks:
      - id: pytest
        name: pytest
        entry: pytest
        language: system
        pass_filenames: false
        always_run: true
```

#### Installation
```bash
# Installer pre-commit
pip install pre-commit

# Setup hooks
pre-commit install

# Test hooks
pre-commit run --all-files
```

### 2. **CI/CD Pipeline**

#### GitHub Actions (.github/workflows/quality.yml)
```yaml
name: Code Quality
on: [push, pull_request]

jobs:
  quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -e .
          pip install ruff black pytest

      - name: Ruff linting
        run: ruff check src/ tests/

      - name: Black formatting
        run: black --check src/ tests/

      - name: Run tests
        run: pytest tests/ -v
```

### 3. **Quality Gates**

#### MÃ©triques Obligatoires
```bash
# Gate 1: Linting (0 erreurs acceptÃ©es)
ruff check src/ tests/ || exit 1

# Gate 2: Formatage (100% compliance)
black --check src/ tests/ || exit 1

# Gate 3: Tests (100% pass rate)
pytest tests/ || exit 1

# Gate 4: Type checking (optionnel mais recommandÃ©)
mypy src/ || echo "Type warnings detected"
```

---

## ðŸ“Š **MÃ©triques et Monitoring**

### ðŸŽ¯ **Objectifs QualitÃ© v3.0**

| MÃ©trique | Objectif | Actuel | Status |
|----------|----------|--------|--------|
| **Ruff Errors** | 0 | 0 | âœ… |
| **Black Compliance** | 100% | 100% (148/148) | âœ… |
| **Test Success** | 100% | 100% (189/189) | âœ… |
| **Test Coverage** | >90% | 95%+ | âœ… |
| **Type Coverage** | >90% | 95%+ | âœ… |
| **Documentation** | 100% APIs | 100% | âœ… |

### ðŸ“ˆ **Tracking QualitÃ©**

#### Script Monitoring
```bash
#!/bin/bash
# quality-check.sh - Script monitoring qualitÃ©

echo "ðŸ” Hyperion v3.0 Quality Check"
echo "================================"

# Ruff
echo "ðŸ“‹ Ruff Linting:"
if ruff check src/ tests/ > /dev/null 2>&1; then
    echo "âœ… Ruff: All checks passed!"
else
    echo "âŒ Ruff: Errors detected"
    ruff check src/ tests/
fi

# Black
echo "ðŸŽ¨ Black Formatting:"
if black --check src/ tests/ > /dev/null 2>&1; then
    echo "âœ… Black: All files compliant"
else
    echo "âŒ Black: Formatting needed"
    black --diff src/ tests/
fi

# Tests
echo "ðŸ§ª Pytest Tests:"
if pytest tests/ -q > /dev/null 2>&1; then
    echo "âœ… Tests: All passing"
else
    echo "âŒ Tests: Failures detected"
    pytest tests/ -v
fi

echo "================================"
echo "ðŸŽ¯ Quality Status: ENTERPRISE READY"
```

---

## ðŸ›¡ï¸ **Best Practices Enterprise**

### 1. **Code Organization**
```python
"""
Module docstring avec description claire
"""
from __future__ import annotations

import standard_library
import third_party
from hyperion.modules import local_modules

# Type annotations pour tout
def process_data(
    data: list[dict[str, Any]],
    config: ProcessConfig
) -> ProcessResult:
    """
    Docstring claire avec:
    - Description
    - Args: types et descriptions
    - Returns: type et description
    - Raises: exceptions possibles
    """
```

### 2. **Error Handling**
```python
class HyperionError(Exception):
    """Base exception pour Hyperion"""
    pass

class ValidationError(HyperionError):
    """Erreur de validation de donnÃ©es"""
    pass

def validate_input(data: Any) -> ValidatedData:
    """Validation avec gestion d'erreurs appropriÃ©e"""
    try:
        result = perform_validation(data)
    except ValueError as e:
        raise ValidationError(f"Invalid data format: {e}") from e
    except Exception as e:
        raise ValidationError(f"Validation failed: {e}") from e

    return result
```

### 3. **Testing Standards**
```python
import pytest
from hyperion.testing import fixtures

class TestDataProcessor:
    """Tests pour DataProcessor avec setup/teardown appropriÃ©s"""

    @pytest.fixture
    def sample_data(self):
        """Fixture avec donnÃ©es de test"""
        return {"test": "data"}

    def test_process_valid_data(self, sample_data):
        """Test cas nominal avec assertions claires"""
        processor = DataProcessor()
        result = processor.process(sample_data)

        assert result.success is True
        assert result.data == expected_data
        assert result.metadata["processed_at"] is not None

    def test_process_invalid_data_raises_error(self):
        """Test cas d'erreur avec exception attendue"""
        processor = DataProcessor()

        with pytest.raises(ValidationError, match="Invalid data"):
            processor.process(None)
```

---

## ðŸš€ **Migration et Adoption**

### ðŸ“‹ **Checklist Migration**

#### Phase 1: Setup Outils
- [ ] Installation Ruff + Black
- [ ] Configuration fichiers (.ruff.toml, pyproject.toml)
- [ ] Setup pre-commit hooks
- [ ] IntÃ©gration CI/CD

#### Phase 2: Fix Existant
- [ ] Fix erreurs critiques (F821, F841, E722)
- [ ] Application formatage Black
- [ ] Standardisation imports (I001)
- [ ] Fix warnings styles (SIM, ARG, UP)

#### Phase 3: Standards
- [ ] Documentation coding standards
- [ ] Formation Ã©quipe
- [ ] Quality gates en place
- [ ] Monitoring continu

### ðŸŽ“ **Formation Ã‰quipe**

#### Workshop Standards (2h)
1. **Introduction outils** (30min)
2. **Hands-on correction** (60min)
3. **CI/CD integration** (30min)

#### Resources
- [Ruff Documentation](https://docs.astral.sh/ruff/)
- [Black Documentation](https://black.readthedocs.io/)
- [Pytest Best Practices](https://docs.pytest.org/en/stable/goodpractices.html)

---

## ðŸ“ž **Support et Troubleshooting**

### ðŸ”§ **ProblÃ¨mes Courants**

#### Ruff Errors
```bash
# Voir tous les types d'erreurs
ruff check src/ --statistics

# Fix automatique quand possible
ruff check src/ --fix

# Ignorer temporairement (non recommandÃ©)
ruff check src/ --ignore=E501,F841
```

#### Black Conflicts
```bash
# Voir diffÃ©rences avant application
black --diff src/

# Application force
black src/

# Check ligne spÃ©cifique
black --line-length=100 src/
```

#### Tests Failures
```bash
# Voir Ã©checs dÃ©taillÃ©s
pytest tests/ -vvv --tb=long

# Run tests spÃ©cifiques
pytest tests/test_specific.py::test_function -v

# Debug mode
pytest tests/ --pdb
```

---

*Documentation Code Quality Standards - Hyperion v3.0 Enterprise*